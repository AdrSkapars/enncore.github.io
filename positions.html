<!DOCTYPE html>
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>News | EnnCore</title>
<meta name="generator" content="Jekyll v3.7.3">
<meta property="og:title" content="EnnCore: End-to-End Conceptual Guarding of Neural Architectures">
<meta property="og:locale" content="en_US">
<meta name="description" content="Security for all in an AI enabled society.">
<meta property="og:description" content="Security for all in an AI enabled society.">
<link rel="canonical" href="https://enncore.github.io/">
<meta property="og:url" content="https://enncore.github.io/">
<meta property="og:site_name" content="EnnCore">
<script type="application/ld+json">
{"name":"EnnCore","description":"Security for all in an AI enabled society.","@type":"WebSite","url":"https://enncore.github.io/","headline":"News","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="./files/style.css">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 id="logo"><a href="https://enncore.github.io/"><img src="logo/logo-enncore.png" style="width: 13vw; min-width: 28px;" alt="logo" /></a></h1>

        <p style="font-size:18px;">End-to-End Conceptual Guarding of Neural Architectures</p>

        <p class="view" style="font-size:16px;">
	  <a href="https://enncore.github.io/news.html"><b>News</b></a><br>
          <a href="https://enncore.github.io/partners.html"><b>Partners</b></a><br>
	  <a href="https://enncore.github.io/positions.html"><b>Positions</b></a><br>
          <a href="https://enncore.github.io/publications.html"><b>Publications</b></a><br>
	  <a href="https://enncore.github.io/people.html"><b>People</b></a><br>
          <a href="https://enncore.github.io/applications.html"><b>Applications</b></a><br>
          <a href="https://enncore.github.io/contrib.html"><b>Third Party Contributions</b></a><br>
	  <a href="https://enncore.github.io/benchmarks.html"><b>Index of Benchmarks</b></a><br>
        </p>

	<!-- <p><a href="https://github.com/esbmc/esbmc/blob/master/src/COPYING"><img src="./files/License-MIT-yellow.svg" alt="License: MIT"></a></p> -->



      </header>
      <section>

      <p style="font-size:16px;">EnnCore will hire four postdoctoral research associates in the areas listed below.</p>

      <h2 id="AutomatedVerification">Automated Verification for Neural Architectures (Manchester and Liverpool)</h2>

      <p style="font-size:16px;">We are looking for two candidates to work on automated verification for neural architectures.</p>

      <p style="font-size:16px;">You will enjoy developing theories, algorithms, and tools for the symbolic verification of deep neural networks and/or the interpretability (explainable AI) of deep neural networks. This position might include techniques based on SMT solvers, abstract interpretation, global optimisation methods, neural-symbolic approaches, etc. In addition to the verification and interpretation of neural network models, you might also consider the verification and analysis of the underlying source code implementation of the neural network.</p>

      <p style="font-size:16px;">You should have, or be about to obtain, a PhD in Computer Science or a closely related field together with an excellent track record of international publications in the foundation and/or application of verification and validation of neural networks. Examples of fields of interests are: </p>

      <ul style="font-size:16px;">
      <li>Automated Verification</li>
      <li>Foundations of Learning</li>
      <li>Reliability Assessment of Neural Networks</li>
      <li>Security of Machine Learning</li>
      <li>Concurrent Systems</li>
      <li>Tool Development</li> 
      </ul>

       <h2 id="ExplainableAI">Safe and Explainable AI Architectures (Manchester)</h2>

      <p style="font-size:16px;">We are looking for one candidate to work on safe and explainable AI architectures.</p>

      <p style="font-size:16px;">You will enjoy developing and evaluating novel theories, algorithms, and tools at the interface between deep neural networks, explainable and safe AI. The project will involve the continuous interaction with experts in formal software verification. You will also have the opportunity to build use cases and to collaborate with domain experts in areas such as cancer research. You will develop and evaluate new models in the context of their accuracy, interpretability and safety. This position may include research on a diverse set of techniques such as neuro-symbolic approaches, explainable AI, adversarial methods and causal inference. </p>

      <p style="font-size:16px;">This position may include research on a diverse set of techniques such as neuro-symbolic approaches, explainable AI, adversarial methods and causal inference.</p>

      </section>
    </div>
    <script src="./files/scale.fix.js.download"></script>



</body></html>
